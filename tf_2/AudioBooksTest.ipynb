{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioBooksTest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeQ-6Ac7eA1J",
        "colab_type": "code",
        "outputId": "13385a92-f633-4f24-9fa2-33536c6b6f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "# Install TensorFlow\n",
        "!pip install tensorflow==2.0.0-beta1\n",
        "!pip install matplotlib\n",
        "!pip install sklearn\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.16.4)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 37.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.4)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta1) (41.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7BVmVrHePvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Code\n",
        "import numpy as np\n",
        "from sklearn import preprocessing \n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5PI-_UdeHQd",
        "colab_type": "text"
      },
      "source": [
        "## Collect the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSaibwrMfwB8",
        "colab_type": "code",
        "outputId": "80a87492-376c-4962-9618-95b727102972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAjQLAs7g0-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data = pd.read_csv('/content/drive/My Drive/machine_learning_data/Audiobooks_data.csv')\n",
        "raw_csv_data = np.loadtxt('/content/drive/My Drive/machine_learning_data/Audiobooks_data.csv', delimiter=',')\n",
        "\n",
        "## data classes here are for balancing 2 categories\n",
        "\n",
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "\n",
        "\n",
        "unscaled_inputs_all = raw_csv_data[:,1:-1]\n",
        "\n",
        "# The targets are in the last column. That's how datasets are conventionally organized.\n",
        "targets_all = raw_csv_data[:,-1]\n",
        "\n",
        "\n",
        "# original source: https://www.dropbox.com/sh/fdqk8i4crvb9ox4/AAB7oVvIDQ7-yOGXTJimyyaJa?dl=0&preview=Audiobooks_data.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfzOaLDhg4Iy",
        "colab_type": "code",
        "outputId": "3bf5ca87-b9b5-416b-a17e-cc3908d404b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "unscaled_inputs_all[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.1600e+03, 2.1600e+03, 1.0130e+01, 1.0130e+01, 0.0000e+00,\n",
              "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "       [1.4040e+03, 2.8080e+03, 6.6600e+00, 1.3330e+01, 1.0000e+00,\n",
              "        6.5000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8200e+02],\n",
              "       [3.2400e+02, 3.2400e+02, 1.0130e+01, 1.0130e+01, 1.0000e+00,\n",
              "        9.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 3.3400e+02],\n",
              "       [1.6200e+03, 1.6200e+03, 1.5310e+01, 1.5310e+01, 0.0000e+00,\n",
              "        9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8300e+02],\n",
              "       [4.3200e+02, 1.2960e+03, 7.1100e+00, 2.1330e+01, 1.0000e+00,\n",
              "        9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "       [2.1600e+03, 2.1600e+03, 1.0130e+01, 1.0130e+01, 1.0000e+00,\n",
              "        9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00],\n",
              "       [1.4040e+03, 2.8080e+03, 6.6700e+00, 1.3330e+01, 0.0000e+00,\n",
              "        7.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0000e+01],\n",
              "       [1.2312e+03, 6.1560e+03, 7.1500e+00, 3.5730e+01, 0.0000e+00,\n",
              "        9.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
              "       [1.1880e+03, 1.1880e+03, 6.9200e+00, 6.9200e+00, 0.0000e+00,\n",
              "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00],\n",
              "       [1.1880e+03, 1.1880e+03, 8.6100e+00, 8.6100e+00, 0.0000e+00,\n",
              "        8.9100e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e+01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vca83FMFq3Ix",
        "colab_type": "text"
      },
      "source": [
        "## Balance Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOIZMhjUhCyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_one_targets = int(np.sum(targets_all))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r890uwGQrCdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero_targets_counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekW6oIFsrF8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_to_remove = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pre5fIjUrHio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count the number of targets that are 0. \n",
        "# Once there are as many 0s as 1s, mark entries where the target is 0.\n",
        "for i in range(targets_all.shape[0]):\n",
        "    if targets_all[i] == 0:\n",
        "        zero_targets_counter += 1\n",
        "        if zero_targets_counter > num_one_targets:\n",
        "            indices_to_remove.append(i)\n",
        "# Create two new variables, one that will contain the inputs, and one that will contain the targets.\n",
        "# We delete all indices that we marked \"to remove\" in the loop above.\n",
        "unscaled_inputs_equal_priors = np.delete(unscaled_inputs_all, indices_to_remove, axis=0)\n",
        "targets_equal_priors = np.delete(targets_all, indices_to_remove, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV9Izu4rtRkv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faxHhoKhrph3",
        "colab_type": "text"
      },
      "source": [
        "## Scale Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvVKQ-Oorqym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_inputs = preprocessing.scale(unscaled_inputs_equal_priors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-7E4DKsry3X",
        "colab_type": "text"
      },
      "source": [
        "## Shuffle things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESdVfrbGrwM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# When the data was collected it was actually arranged by date\n",
        "# Shuffle the indices of the data, so the data is not arranged in any way when we feed it.\n",
        "# Since we will be batching, we want the data to be as randomly spread out as possible\n",
        "shuffled_indices = np.arange(scaled_inputs.shape[0])\n",
        "np.random.shuffle(shuffled_indices)\n",
        "\n",
        "# Use the shuffled indices to shuffle the inputs and targets.\n",
        "shuffled_inputs = scaled_inputs[shuffled_indices]\n",
        "shuffled_targets = targets_equal_priors[shuffled_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNL-xOMisNss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nzOB5EsGpy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdMs29aBGqzu",
        "colab_type": "text"
      },
      "source": [
        "Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8bN5cttGsdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e1483d5b-f3d3-4c53-a6d5-73b7cfc7ee76"
      },
      "source": [
        "samples_count = shuffled_inputs.shape[0]\n",
        "train_samples_count = int(0.8*samples_count)\n",
        "validation_samples_count = int(0.1*samples_count)\n",
        "test_samples_count = samples_count - train_samples_count - validation_samples_count\n",
        "\n",
        "train_inputs = shuffled_inputs[:train_samples_count]\n",
        "train_targets = shuffled_targets[:train_samples_count]\n",
        "\n",
        "validation_inputs = shuffled_inputs[train_samples_count:train_samples_count + validation_samples_count]\n",
        "validation_targets = shuffled_targets[train_samples_count:train_samples_count + validation_samples_count]\n",
        "\n",
        "test_inputs = shuffled_inputs[train_samples_count + validation_samples_count:]\n",
        "test_targets = shuffled_targets[train_samples_count + validation_samples_count:]\n",
        "\n",
        "## We want priors to be close to 50%\n",
        "\n",
        "print(np.sum(train_targets), train_samples_count, np.sum(train_targets) / train_samples_count)\n",
        "print(np.sum(validation_targets), validation_samples_count, np.sum(validation_targets) / validation_samples_count)\n",
        "print(np.sum(test_targets), test_samples_count, np.sum(test_targets) / test_samples_count)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1799.0 3579 0.5026543727298128\n",
            "217.0 447 0.4854586129753915\n",
            "221.0 448 0.49330357142857145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSWs8YXYIwRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez('Audiobooks_data_train', inputs=train_inputs, targets=train_targets)\n",
        "np.savez('Audiobooks_data_validation', inputs=validation_inputs, targets=validation_targets)\n",
        "np.savez('Audiobooks_data_test', inputs=test_inputs, targets=test_targets)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}